# 왜 토큰화를 해야 하는가?

## 결론: 컴퓨터는 글자를 이해 못하고 숫자만 이해합니다.

---

## 토큰화란?

텍스트를 작은 조각(토큰)으로 나누고, 각 조각에 숫자(ID)를 붙이는 것입니다.

```
"서울에서 React 채용"
    ↓ 토큰으로 나누기
["서울", "에서", " ", "React", " ", "채용"]
    ↓ ID 부여
[1523, 892, 3, 4521, 3, 1876]
```

---

## 왜 필요한가?

### 1. GPT 학습 방식

GPT는 **"다음 토큰 맞추기"** 게임으로 학습합니다.

```
입력: [1523, 892, 3]     ("서울에서 ")
예측: 4521               ("React")
```

맞추려면 숫자여야 확률 계산이 됩니다.

### 2. 임베딩 입력

모델 내부에서 **토큰 ID → 벡터 변환**이 일어납니다.

```
토큰 ID 1523 → [0.1, -0.3, 0.7, ..., 0.2]  (384차원 벡터)
```

토큰화 없이는 모델에 입력할 수 없습니다.

### 3. 효율성

도메인 특화 토크나이저는 **"USD 150k"를 3개 토큰**으로, 범용은 7개로 쪼갭니다.

| 토크나이저 | "USD 150k" 토큰화 |
|-----------|-------------------|
| 도메인 특화 | ["USD", " ", "150k"] (3개) |
| 범용 | ["U", "SD", " ", "1", "50", "k"] (6개) |

토큰이 적으면 계산도 빠르고 의미도 보존됩니다.

---

## BPE (Byte Pair Encoding) 알고리즘

JAI에서 사용하는 토큰화 방식입니다.

### 동작 원리

```
1. 초기: 모든 문자를 개별 토큰으로 시작
   "안녕하세요" → ["안", "녕", "하", "세", "요"]

2. 반복: 가장 자주 등장하는 연속 쌍을 병합
   ("안", "녕") 빈도 높음 → ["안녕", "하", "세", "요"]
   ("하", "세") 빈도 높음 → ["안녕", "하세", "요"]

3. 종료: vocab_size에 도달할 때까지 반복
```

### vocab_size 설정

| 값 | 결과 |
|----|------|
| 너무 작음 (8,000) | 한국어가 글자 단위로 쪼개짐 |
| 너무 큼 (100,000) | 희소한 토큰이 많아 학습 어려움 |
| **권장 (16,000~32,000)** | 적절한 균형 |

JAI 기본값: **24,000**

---

## 토크나이저 테스트 예시

```python
from tokenizers import Tokenizer

tokenizer = Tokenizer.from_file("data/tokenizer.json")

text = "서울에서 React 개발자 채용"
encoded = tokenizer.encode(text)

print(f"원본: {text}")
print(f"토큰: {encoded.tokens}")
print(f"ID: {encoded.ids}")
```

출력:
```
원본: 서울에서 React 개발자 채용
토큰: ['서울', '에서', ' ', 'React', ' ', '개발자', ' ', '채용']
ID: [1523, 892, 3, 4521, 3, 2847, 3, 1876]
```

---

## 요약

| 질문 | 답변 |
|------|------|
| 토큰화가 필요한 이유 | 컴퓨터는 숫자만 처리 가능 |
| 토큰화 방식 | BPE (Byte Pair Encoding) |
| vocab_size 권장값 | 16,000 ~ 32,000 |
| JAI 기본값 | 24,000 |

---

## 관련 문서

- [토큰화 방법](how-to-tokenize.md)
- [vocab_size란?](vocab-size.md)
- [토큰화 다음 단계](after-tokenize.md)
- [핵심 개념 - 토크나이저](core-concepts.md#1-tokenizer-토크나이저)
- [트러블슈팅 - 토크나이저 문제](troubleshooting.md#토크나이저-문제)
